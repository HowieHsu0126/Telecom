{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras.tabular import TabularPreprocessor\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "dataset_version = 50\n",
    "\n",
    "train_data = pd.read_csv(\n",
    "    f'/home/hwxu/Projects/Competition/Telecom/Input/processed/train{dataset_version}.csv')\n",
    "validation_data = pd.read_csv(\n",
    "    f'/home/hwxu/Projects/Competition/Telecom/Input/processed/val{dataset_version}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dftrain_raw, dfval_raw = train_test_split(\n",
    "    train_data, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras.tabular import TabularDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "target_col = 'is_sa'\n",
    "numeric_cols = validation_data.select_dtypes(\n",
    "    include=['float64', 'int64']).columns.tolist()\n",
    "cat_cols = validation_data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "pipe = TabularPreprocessor(cat_features=cat_cols,\n",
    "                           numeric_features=numeric_cols)\n",
    "\n",
    "dffull = pipe.fit_transform(train_data.drop(\n",
    "    target_col, axis=1)).join(train_data[target_col])\n",
    "dftrain = pipe.fit_transform(dftrain_raw.drop(\n",
    "    target_col, axis=1)).join(train_data[target_col])\n",
    "dfval = pipe.transform(dfval_raw.drop(target_col, axis=1)\n",
    "                       ).join(train_data[target_col])\n",
    "dftest = pipe.transform(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dfdata):\n",
    "    return TabularDataset(\n",
    "        data=dfdata,\n",
    "        task='classification',\n",
    "        target=[target_col],\n",
    "        continuous_cols=pipe.get_numeric_features(),\n",
    "        categorical_cols=pipe.get_embedding_features()\n",
    "    )\n",
    "\n",
    "\n",
    "def get_dataloader(ds, batch_size=1024, num_workers=0, shuffle=False):\n",
    "    dl = DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    return dl\n",
    "\n",
    "ds_full = get_dataset(dffull)\n",
    "ds_train = get_dataset(dftrain)\n",
    "ds_val = get_dataset(dfval)\n",
    "ds_test = TabularDataset(dftest, task='classification', continuous_cols=pipe.get_numeric_features(\n",
    "), categorical_cols=pipe.get_embedding_features())\n",
    "\n",
    "dl_full = get_dataloader(ds_full, shuffle=True)\n",
    "dl_train = get_dataloader(ds_train, shuffle=True)\n",
    "dl_val = get_dataloader(ds_val, shuffle=False)\n",
    "dl_test = get_dataloader(ds_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras.tabular.models import FTTransformerConfig, FTTransformerModel\n",
    "\n",
    "model_config = FTTransformerConfig(\n",
    "    task=\"classification\",\n",
    "    num_attn_blocks=3\n",
    ")\n",
    "\n",
    "config = model_config.merge_dataset_config(ds_train)\n",
    "net = FTTransformerModel(config=config)\n",
    "\n",
    "# 初始化参数\n",
    "net.reset_weights()\n",
    "net.data_aware_initialization(dl_train)\n",
    "\n",
    "print(net.backbone.output_dim)\n",
    "print(net.hparams.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras import KerasModel\n",
    "from torchkeras.tabular import StepRunner\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "KerasModel.StepRunner = StepRunner\n",
    "\n",
    "\n",
    "class BinaryF1Score(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tp = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "        self.fp = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "        self.tn = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "        self.fn = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "\n",
    "    def forward(self, preds: torch.Tensor, targets: torch.Tensor):\n",
    "        preds = preds.argmax(dim=-1)\n",
    "        targets = targets.reshape(-1)\n",
    "        tp = ((preds == 1) & (targets == 1)).sum()\n",
    "        fp = ((preds == 1) & (targets == 0)).sum()\n",
    "        tn = ((preds == 0) & (targets == 0)).sum()\n",
    "        fn = ((preds == 0) & (targets == 1)).sum()\n",
    "        self.tp += tp\n",
    "        self.fp += fp\n",
    "        self.tn += tn\n",
    "        self.fn += fn\n",
    "        # return f1\n",
    "        return 2 * tp.float() / (2 * tp + fp + fn).float()\n",
    "\n",
    "    def compute(self):\n",
    "        precision = self.tp.float() / (self.tp + self.fp).float()\n",
    "        recall = self.tp.float() / (self.tp + self.fn).float()\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        return f1\n",
    "\n",
    "    def reset(self):\n",
    "        self.tp -= self.tp\n",
    "        self.fp -= self.fp\n",
    "        self.tn -= self.tn\n",
    "        self.fn -= self.fn\n",
    "\n",
    "\n",
    "keras_model = KerasModel(net,\n",
    "                         loss_fn=None,\n",
    "                         optimizer=torch.optim.AdamW(\n",
    "                             net.parameters(), lr=1e-3),\n",
    "                         metrics_dict={\"f1\": BinaryF1Score()}\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.fit(\n",
    "    train_data=dl_train,\n",
    "    val_data=dl_val,\n",
    "    ckpt_path=f'/home/hwxu/Projects/Competition/Telecom/Output/ckpt/ft_transformer_{datetime.now()}.ckpt',\n",
    "    epochs=200,\n",
    "    patience=10,\n",
    "    monitor=\"val_f1\",\n",
    "    mode=\"max\",\n",
    "    plot=True,\n",
    "    wandb=False,\n",
    "    cpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-train\n",
    "keras_model.fit(\n",
    "    train_data=dl_full,\n",
    "    val_data=dl_val,\n",
    "    ckpt_path=f'/home/hwxu/Projects/Competition/Telecom/Output/ckpt/retrain_ft_transformer_{datetime.now()}.ckpt',\n",
    "    epochs=200,\n",
    "    patience=10,\n",
    "    mode=\"max\",\n",
    "    plot=True,\n",
    "    wandb=False,\n",
    "    cpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Load model and predict\n",
    "keras_model.load_ckpt('/home/hwxu/Projects/Competition/Telecom/Output/ckpt/ft_transformer_2024-07-27 02:30:25.504504.ckpt')\n",
    "net = keras_model.net\n",
    "preds = []\n",
    "for batch in tqdm(dl_test):\n",
    "    preds.append(net.predict(batch))\n",
    "yhat_list = [yd.argmax(dim=-1).tolist() for yd in preds]\n",
    "yhat = []\n",
    "for yd in yhat_list:\n",
    "    yhat.extend(yd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msisdn = validation_data['msisdn']\n",
    "output_path = f'/home/hwxu/Projects/Competition/Telecom/Output/submissions/ftt-pred-{dataset_version}_{datetime.now()}.csv'\n",
    "result = pd.DataFrame({'msisdn': msisdn, 'is_sa': yhat})\n",
    "result.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
