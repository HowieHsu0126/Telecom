{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedGroupKFold\n",
    "\n",
    "base_models = [\n",
    "    ('xgboost', XGBClassifier(learning_rate=0.1, max_depth=9,\n",
    "     min_child_weight=9, n_estimators=100, n_jobs=-1, subsample=0.6)),\n",
    "]\n",
    "meta_model = XGBClassifier(\n",
    "    n_estimators=125,\n",
    "    max_depth=4,\n",
    "    min_child_weight=2,\n",
    "    gamma=0.9,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=1\n",
    ")\n",
    "\n",
    "\n",
    "def prepare_data(data):\n",
    "    X = data.drop(columns=['is_sa'])\n",
    "    y = data['is_sa']\n",
    "    groups = data['msisdn']\n",
    "    return X, y, groups\n",
    "\n",
    "\n",
    "def build_stacking_classifier():\n",
    "    final_estimator = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=base_models,\n",
    "        final_estimator=final_estimator,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    return stacking_clf\n",
    "\n",
    "\n",
    "def build_voting_classifier():\n",
    "    voting_clf = VotingClassifier(\n",
    "        estimators=base_models,\n",
    "        voting='soft',\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    return voting_clf\n",
    "\n",
    "\n",
    "def build_simple_classifier():\n",
    "    return base_models[0][1]\n",
    "\n",
    "\n",
    "def build_model(mode='stacking'):\n",
    "    if mode == 'stacking':\n",
    "        return build_stacking_classifier()\n",
    "    elif mode == 'simple':\n",
    "        return build_simple_classifier()\n",
    "    elif mode == 'voting':\n",
    "        return build_voting_classifier()\n",
    "    else:\n",
    "        raise ValueError(f'Unknown mode: {mode}')\n",
    "\n",
    "\n",
    "def cross_validate_model(model, X, y, groups, cv_strategy):\n",
    "    cv_scores = cross_val_score(model, X, y, cv=cv_strategy, groups=groups)\n",
    "    print(f'Cross-validation F1 score: {cv_scores.mean()}')\n",
    "    return cv_scores\n",
    "\n",
    "\n",
    "def predict_and_save(model, validation_data, output_path, threshold=0.5):\n",
    "    y_proba = model.predict_proba(validation_data)\n",
    "    y_pred = (y_proba[:, 1] > threshold).astype(int)\n",
    "    validation_data['is_sa'] = y_pred\n",
    "    validation_data[['msisdn', 'is_sa']].to_csv(output_path, index=False)\n",
    "\n",
    "\n",
    "def pseudo_labeling(train_data, validation_data, threshold=0.9, mode='voting'):\n",
    "    X_train, y_train, groups_train = prepare_data(train_data)\n",
    "    X_unlabeled = validation_data.copy()\n",
    "\n",
    "    model = build_model(mode)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_unlabeled_pred = model.predict_proba(X_unlabeled)\n",
    "    high_confidence_indices = (y_unlabeled_pred.max(axis=1) > threshold)\n",
    "\n",
    "    pseudo_labeled_data = validation_data[high_confidence_indices].copy()\n",
    "    pseudo_labeled_data['is_sa'] = y_unlabeled_pred[high_confidence_indices].argmax(\n",
    "        axis=1)\n",
    "\n",
    "    augmented_train_data = pd.concat(\n",
    "        [train_data, pseudo_labeled_data], ignore_index=True)\n",
    "\n",
    "    return augmented_train_data\n",
    "\n",
    "\n",
    "def main(train_data, validation_data, output_path, use_pseudo_labeling=False, threshold=0.95, mode='voting', n_fold=5, need_prediction=False, pred_threshold=0.5):\n",
    "    if use_pseudo_labeling:\n",
    "        augmented_train_data = pseudo_labeling(\n",
    "            train_data, validation_data, threshold, mode)\n",
    "    else:\n",
    "        augmented_train_data = train_data\n",
    "\n",
    "    X, y, groups = prepare_data(augmented_train_data)\n",
    "    cv_strategy = StratifiedGroupKFold(n_splits=n_fold)\n",
    "\n",
    "    classifier = build_model(mode)\n",
    "\n",
    "    cross_validate_model(classifier, X, y, groups, cv_strategy)\n",
    "\n",
    "    if need_prediction:\n",
    "        classifier.fit(X, y)\n",
    "        predict_and_save(classifier, validation_data,\n",
    "                         output_path, threshold=pred_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "output_path = f'/home/hwxu/Projects/Competition/Telecom/Output/submissions/new_pred_{datetime.now()}.csv'\n",
    "train_data = pd.read_csv(\n",
    "    '/home/hwxu/Projects/Competition/Telecom/Input/processed/train35.csv')\n",
    "validation_data = pd.read_csv(\n",
    "    '/home/hwxu/Projects/Competition/Telecom/Input/processed/val35.csv')\n",
    "print(\n",
    "    f\"Training on {train_data.shape[0]} samples with {validation_data.shape[1]} features.\")\n",
    "\n",
    "main(\n",
    "    train_data,\n",
    "    validation_data,\n",
    "    output_path,\n",
    "    use_pseudo_labeling=False,\n",
    "    threshold=0.95,\n",
    "    mode='simple',\n",
    "    n_fold=5,\n",
    "    need_prediction=True,\n",
    "    pred_threshold=0.5,\n",
    ")\n",
    "# 0.9170992231638418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv(\n",
    "    '/home/hwxu/Projects/Competition/Telecom/Input/processed/train30.csv')\n",
    "validation_data = pd.read_csv(\n",
    "    '/home/hwxu/Projects/Competition/Telecom/Input/processed/val30.csv')\n",
    "X, y = train_data.drop(columns=['is_sa']), train_data['is_sa']\n",
    "print(f\"Training on {X.shape[0]} samples with {validation_data.shape[1]} features.\")\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "search_space = {\n",
    "    'tree_method': ['hist'],  \n",
    "    'lambda': list(np.logspace(-3, 1, 100)),  \n",
    "    'alpha': list(np.logspace(-3, 1, 100)), \n",
    "    'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  \n",
    "    'subsample': [0.4, 0.5, 0.6, 0.7, 0.8, 1.0], \n",
    "    'learning_rate': [0.008, 0.01, 0.012, 0.014, 0.016, 0.018, 0.02], \n",
    "    'n_estimators': [100, 200, 500, 1000], \n",
    "    'max_depth': [5, 7, 9, 11, 13, 15, 17],  \n",
    "    'min_child_weight': list(np.arange(1, 301, 1)),  \n",
    "    'random_state': [42],\n",
    "    'device': ['gpu'],\n",
    "    'n_jobs': [-1],\n",
    "}\n",
    "\n",
    "grid = HalvingGridSearchCV(\n",
    "    estimator=xgb_model, \n",
    "    cv=StratifiedGroupKFold(n_splits=5), \n",
    "    param_grid=search_space,\n",
    "    scoring='f1', \n",
    "    verbose=0, \n",
    "    n_jobs=-1, \n",
    "    refit=True)\n",
    "\n",
    "grid.fit(X, y, groups=X['msisdn'])\n",
    "\n",
    "print(\"Best Score:\" + str(grid.best_score_))\n",
    "print(\"Best Parameters: \" + str(grid.best_params_))\n",
    "\n",
    "best_parameters = grid.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hwxu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
