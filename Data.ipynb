{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from category_encoders import HashingEncoder, CountEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self):\n",
    "        self.encoders = {}\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    @staticmethod\n",
    "    def _convert_time_columns(data):\n",
    "        data['start_time'] = pd.to_datetime(\n",
    "            data['start_time'], format='%Y%m%d%H%M%S')\n",
    "        data['end_time'] = pd.to_datetime(\n",
    "            data['end_time'], format='%Y%m%d%H%M%S')\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_time_features(data):\n",
    "        data['start_hour'] = data['start_time'].dt.hour\n",
    "        data['start_dayofweek'] = data['start_time'].dt.dayofweek\n",
    "        data['is_weekend'] = data['start_dayofweek'].apply(\n",
    "            lambda x: 1 if x >= 5 else 0)\n",
    "        data['is_working_hour'] = data['start_hour'].apply(\n",
    "            lambda x: 1 if 9 <= x <= 18 else 0)\n",
    "        return data\n",
    "\n",
    "    def _encode_categorical_features(self, data, encoding_config):\n",
    "        for feature, encoding_method in encoding_config.items():\n",
    "            if encoding_method == 'onehot':\n",
    "                encoder = OneHotEncoder(\n",
    "                    sparse_output=False, handle_unknown='ignore')\n",
    "                encoded = encoder.fit_transform(data[[feature]])\n",
    "                encoded_df = pd.DataFrame(\n",
    "                    encoded, columns=[f\"{feature}_{cat}\" for cat in encoder.categories_[0]])\n",
    "                data = pd.concat([data, encoded_df], axis=1)\n",
    "                data.drop(columns=[feature], inplace=True)\n",
    "            elif encoding_method == 'label':\n",
    "                encoder = OrdinalEncoder(\n",
    "                    handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "                encoded = encoder.fit_transform(data[[feature]])\n",
    "                data[feature] = encoded\n",
    "            elif encoding_method == 'hash':\n",
    "                encoder = HashingEncoder()\n",
    "                encoded = encoder.fit_transform(data[[feature]])\n",
    "                data = pd.concat([data, encoded], axis=1)\n",
    "            elif encoding_method == 'count':\n",
    "                encoder = CountEncoder()\n",
    "                encoded = encoder.fit_transform(data[[feature]])\n",
    "                data[feature] = encoded\n",
    "            elif encoding_method == 'labelcount':\n",
    "                encoder = CountEncoder(normalize=True)\n",
    "                encoded = encoder.fit_transform(data[[feature]])\n",
    "                data[feature] = encoded\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown encoding method: {encoding_method}\")\n",
    "            self.encoders[feature] = encoder\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistical_features(df, feature):\n",
    "        return df.groupby('msisdn')[feature].agg([\n",
    "            'sum', \n",
    "            'mean', \n",
    "            'max', \n",
    "            'min', \n",
    "            'std', \n",
    "            'var', \n",
    "            'median', \n",
    "            'nunique', \n",
    "            'size', \n",
    "            'count',\n",
    "            # ('skew', lambda x: skew(x) if len(x) > 1 else np.nan),\n",
    "            # ('kurt', lambda x: kurtosis(x) if len(x) > 1 else np.nan),\n",
    "            ('quantile_25', lambda x: x.quantile(0.25)),\n",
    "            ('quantile_75', lambda x: x.quantile(0.75)),\n",
    "            ('mode', lambda x: x.mode().iloc[0]\n",
    "             if not x.mode().empty else np.nan)\n",
    "        ]).add_prefix(f'{feature}_')\n",
    "\n",
    "    @staticmethod\n",
    "    def _aggregate_numerical_features(data, numerical_features):\n",
    "        user_aggregated_data = pd.DataFrame()\n",
    "        for feature in numerical_features:\n",
    "            feature_stats = DataProcessor._statistical_features(data, feature)\n",
    "            if user_aggregated_data.empty:\n",
    "                user_aggregated_data = feature_stats\n",
    "            else:\n",
    "                user_aggregated_data = user_aggregated_data.join(\n",
    "                    feature_stats, how='outer')\n",
    "        return user_aggregated_data\n",
    "\n",
    "    @staticmethod\n",
    "    def _aggregate_categorical_frequencies(data, categorical_features, user_aggregated_data):\n",
    "        categorical_features = [\n",
    "            'call_event', 'roam_type', 'long_type1', 'ismultimedia',  'phone1_type', 'phone2_type', 'is_weekend', 'is_working_hour',\n",
    "        ]\n",
    "        for feature in categorical_features:\n",
    "            frequency = data.groupby(\n",
    "                ['msisdn', feature]).size().unstack(fill_value=0)\n",
    "            normalized_frequency = frequency.div(frequency.sum(axis=1), axis=0)\n",
    "            normalized_frequency.columns = [\n",
    "                f\"{feature}_{col}_freq\" for col in normalized_frequency.columns]\n",
    "            user_aggregated_data = user_aggregated_data.join(\n",
    "                normalized_frequency, how='left')\n",
    "        return user_aggregated_data\n",
    "\n",
    "    @staticmethod\n",
    "    def _aggregate_differential_features(data):\n",
    "        data['call_duration_diff'] = data.groupby(\n",
    "            'msisdn')['call_duration'].diff().fillna(0)\n",
    "        data['call_duration_diff2'] = data.groupby(\n",
    "            'msisdn')['call_duration'].diff(2).fillna(0)\n",
    "\n",
    "        diff_agg_funcs = {\n",
    "            'call_duration_diff': ['mean', 'std'],\n",
    "            'call_duration_diff2': ['mean', 'std']\n",
    "        }\n",
    "\n",
    "        diff_aggregated_data = data.groupby('msisdn').agg(diff_agg_funcs)\n",
    "        diff_aggregated_data.columns = [\n",
    "            '_'.join(map(str, col)).strip() for col in diff_aggregated_data.columns.values]\n",
    "\n",
    "        return diff_aggregated_data\n",
    "\n",
    "    @staticmethod\n",
    "    def _binary_operations(user_aggregated_data):\n",
    "        if 'cfee_sum' in user_aggregated_data.columns and 'lfee_sum' in user_aggregated_data.columns:\n",
    "            user_aggregated_data['cfee_lfee_sum'] = user_aggregated_data['cfee_sum'] + \\\n",
    "                user_aggregated_data['lfee_sum']\n",
    "            user_aggregated_data['cfee_lfee_diff'] = user_aggregated_data['cfee_sum'] - \\\n",
    "                user_aggregated_data['lfee_sum']\n",
    "            user_aggregated_data['cfee_lfee_prod'] = user_aggregated_data['cfee_sum'] * \\\n",
    "                user_aggregated_data['lfee_sum']\n",
    "            user_aggregated_data['cfee_lfee_ratio'] = user_aggregated_data['cfee_sum'] / (\n",
    "                user_aggregated_data['lfee_sum'] + 1e-6)\n",
    "        return user_aggregated_data\n",
    "\n",
    "    def preprocess_and_aggregate(self, data, label_data=None, is_validation=False, fit_columns=None, encoding_config=None):\n",
    "        data = self._convert_time_columns(data)\n",
    "        data = self._extract_time_features(data)\n",
    "\n",
    "        # 疑似类型标志\n",
    "        suspect_types = {3, 5, 6, 9, 11, 12, 17}\n",
    "        data['is_suspect'] = data['phone1_type'].apply(\n",
    "            lambda x: 1 if x in suspect_types else 0)\n",
    "\n",
    "        categorical_features = [\n",
    "            'call_event', 'roam_type', 'long_type1', 'ismultimedia', 'home_area_code',\n",
    "            'visit_area_code', 'called_home_code', 'called_code', 'a_serv_type',\n",
    "            'a_product_id', 'phone1_type', 'phone2_type', 'phone1_loc_city',\n",
    "            'phone1_loc_province', 'phone2_loc_city', 'phone2_loc_province',\n",
    "            'is_weekend', 'is_working_hour'\n",
    "        ]\n",
    "        data = self._encode_categorical_features(data, encoding_config)\n",
    "\n",
    "        numerical_features = ['call_duration', 'cfee',\n",
    "                              'lfee', 'start_hour', 'start_dayofweek']\n",
    "        user_aggregated_data = self._aggregate_numerical_features(\n",
    "            data, numerical_features)\n",
    "        user_aggregated_data = self._aggregate_categorical_frequencies(\n",
    "            data, categorical_features, user_aggregated_data)\n",
    "        diff_aggregated_data = self._aggregate_differential_features(data)\n",
    "        user_aggregated_data = user_aggregated_data.join(\n",
    "            diff_aggregated_data, how='left')\n",
    "\n",
    "        user_aggregated_data = self._binary_operations(user_aggregated_data)\n",
    "        user_aggregated_data.fillna(0, inplace=True)\n",
    "        user_aggregated_data.reset_index(inplace=True)\n",
    "\n",
    "        if not is_validation and label_data is not None:\n",
    "            user_aggregated_data = user_aggregated_data.merge(\n",
    "                label_data, on='msisdn', how='left')\n",
    "\n",
    "        if not is_validation:\n",
    "            numerical_features = [\n",
    "                col for col in user_aggregated_data.columns if col not in ['msisdn', 'is_sa']]\n",
    "            user_aggregated_data[numerical_features] = self.scaler.fit_transform(\n",
    "                user_aggregated_data[numerical_features])\n",
    "            return user_aggregated_data, numerical_features, self.scaler\n",
    "        else:\n",
    "            user_aggregated_data[fit_columns] = self.scaler.transform(\n",
    "                user_aggregated_data[fit_columns])\n",
    "            return user_aggregated_data\n",
    "\n",
    "\n",
    "def feature_selection(train_data, label_column='is_sa', k=20):\n",
    "    X = train_data.drop(columns=['msisdn', label_column])\n",
    "    y = train_data[label_column]\n",
    "\n",
    "    # XGBoost feature importance\n",
    "    xgb_model = XGBClassifier(eval_metric='logloss', n_jobs=-1)\n",
    "    xgb_model.fit(X, y)\n",
    "    xgb_feature_scores = pd.Series(\n",
    "        xgb_model.feature_importances_, index=X.columns)\n",
    "    xgb_selected_features = xgb_feature_scores.nlargest(k).index.tolist()\n",
    "\n",
    "    # Mutual information\n",
    "    mutual_info_scores = mutual_info_classif(X, y)\n",
    "    mutual_info_series = pd.Series(mutual_info_scores, index=X.columns)\n",
    "    mutual_info_selected_features = mutual_info_series.nlargest(\n",
    "        k).index.tolist()\n",
    "\n",
    "    # Recursive feature elimination\n",
    "    rfe_model = LogisticRegression(max_iter=1000)\n",
    "    rfe = RFE(rfe_model, n_features_to_select=k)\n",
    "    rfe.fit(X, y)\n",
    "    rfe_selected_features = X.columns[rfe.support_].tolist()\n",
    "\n",
    "    # Combine selected features from all methods\n",
    "    combined_features = list(set(\n",
    "        xgb_selected_features + mutual_info_selected_features + rfe_selected_features))\n",
    "\n",
    "    return combined_features\n",
    "\n",
    "\n",
    "# Encoding configuration with Count Encoding for location features\n",
    "encoding_config = {\n",
    "    'call_event': 'label',          # 通话类型：label encoding\n",
    "    'other_party': 'label',          # 对端标识号2：label encoding\n",
    "    'ismultimedia': 'label',        # 视频呼叫标志：label encoding\n",
    "    'home_area_code': 'count',      # 归属地区号：count encoding\n",
    "    'visit_area_code': 'count',     # 到访地区号：count encoding\n",
    "    'called_home_code': 'count',    # 对端归属区号：count encoding\n",
    "    'called_code': 'count',         # 对端到访区号：count encoding\n",
    "    'a_serv_type': 'onehot',        # 用户业务类型：one hot encoding\n",
    "    'long_type1': 'label',          # 长途类型1：label encoding\n",
    "    'roam_type': 'label',           # 漫游类型：label encoding\n",
    "    'a_product_id': 'count',        # 产品编码：count encoding\n",
    "    'phone1_type': 'label',         # 标识号1类型：label encoding\n",
    "    'phone2_type': 'label',         # 对端标识号2类型：label encoding\n",
    "    'phone1_loc_city': 'count',     # 标识号1的通话所在地：count encoding\n",
    "    'phone1_loc_province': 'count',  # 标识号1的通话所在省：count encoding\n",
    "    'phone2_loc_city': 'count',     # 对端标识号2的通话所在地：count encoding\n",
    "    'phone2_loc_province': 'count',  # 对端标识号2的通话所在省：count encoding\n",
    "    'is_weekend': 'label',          # 是否周末：label encoding\n",
    "    'is_working_hour': 'label'      # 是否工作时间：label encoding\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "train_set_res = pd.read_csv(\n",
    "    '/home/hwxu/Projects/Competition/Telecom/Input/raw/train.csv', low_memory=False)\n",
    "train_set_ans = pd.read_csv(\n",
    "    '/home/hwxu/Projects/Competition/Telecom/Input/raw/labels.csv', low_memory=False)\n",
    "validation_set_res = pd.read_csv(\n",
    "    '/home/hwxu/Projects/Competition/Telecom/Input/raw/val.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化数据处理器\n",
    "data_processor = DataProcessor()\n",
    "\n",
    "# 处理训练集\n",
    "train_data, fit_columns, scaler = data_processor.preprocess_and_aggregate(\n",
    "    train_set_res, train_set_ans, is_validation=False, encoding_config=encoding_config)\n",
    "\n",
    "# 选择特征\n",
    "selected_features = feature_selection(train_data, k=50)\n",
    "train_data = train_data[['msisdn'] + selected_features + ['is_sa']]\n",
    "\n",
    "# 处理验证集\n",
    "validation_data = data_processor.preprocess_and_aggregate(\n",
    "    validation_set_res, is_validation=True, fit_columns=fit_columns, encoding_config=encoding_config)\n",
    "\n",
    "# 选择特征（根据训练集选择的特征）\n",
    "validation_data = validation_data[['msisdn'] + selected_features]\n",
    "\n",
    "# 输出处理后的训练集和验证集\n",
    "train_data.to_csv(\n",
    "    '/home/hwxu/Projects/Competition/Telecom/Input/processed/train.csv', index=False)\n",
    "validation_data.to_csv(\n",
    "    '/home/hwxu/Projects/Competition/Telecom/Input/processed/val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape, validation_data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hwxu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
